{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import os.path as ops\n",
    "import argparse\n",
    "import time\n",
    "import math\n",
    "\n",
    "import tensorflow as tf\n",
    "import glob\n",
    "import glog as log\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "from lanenet_model import lanenet_merge_model\n",
    "from lanenet_model import lanenet_cluster\n",
    "from lanenet_model import lanenet_postprocess\n",
    "from config import global_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = global_config.cfg\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale(input_arr):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input_arr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    min_val = np.min(input_arr)\n",
    "    max_val = np.max(input_arr)\n",
    "\n",
    "    output_arr = (input_arr - min_val) * 255.0 / (max_val - min_val)\n",
    "    return output_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_lanenet_batch(image_dir, weights_path, batch_size, use_gpu, save_dir=None):\n",
    "    \"\"\"h \n",
    "\n",
    "    :param image_dir:\n",
    "    :param weights_path:\n",
    "    :param batch_size:\n",
    "    :param use_gpu:\n",
    "    :param save_dir:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert ops.exists(image_dir), '{:s} not exist'.format(image_dir)\n",
    "\n",
    "    log.info('Start getting the image file path...')\n",
    "    image_path_list = glob.glob('{:s}/**/*.jpg'.format(image_dir), recursive=True) + \\\n",
    "                      glob.glob('{:s}/**/*.png'.format(image_dir), recursive=True) + \\\n",
    "                      glob.glob('{:s}/**/*.jpeg'.format(image_dir), recursive=True)\n",
    "\n",
    "    input_tensor = tf.placeholder(dtype=tf.float32, shape=[None, 256, 512, 3], name='input_tensor')\n",
    "    phase_tensor = tf.constant('test', tf.string)\n",
    "\n",
    "    net = lanenet_merge_model.LaneNet(phase=phase_tensor, net_flag='vgg')\n",
    "    binary_seg_ret, instance_seg_ret = net.inference(input_tensor=input_tensor, name='lanenet_model')\n",
    "\n",
    "    cluster = lanenet_cluster.LaneNetCluster()\n",
    "    postprocessor = lanenet_postprocess.LaneNetPoseProcessor()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Set sess configuration\n",
    "    if use_gpu:\n",
    "        sess_config = tf.ConfigProto(device_count={'GPU': 1})\n",
    "    else:\n",
    "        sess_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "        \n",
    "    sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TEST.GPU_MEMORY_FRACTION\n",
    "    sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "    sess_config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "    sess = tf.Session(config=sess_config)\n",
    "\n",
    "    with sess.as_default():\n",
    "\n",
    "        saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "        epoch_nums = int(math.ceil(len(image_path_list) / batch_size))\n",
    "\n",
    "        for epoch in range(epoch_nums):\n",
    "            log.info('[Epoch:{:d}] Start image reading and preprocessing...'.format(epoch))\n",
    "            \n",
    "            t_start = time.time()\n",
    "            image_path_epoch = image_path_list[epoch * batch_size:(epoch + 1) * batch_size]\n",
    "            image_list_epoch = [cv2.imread(tmp, cv2.IMREAD_COLOR) for tmp in image_path_epoch]\n",
    "            image_vis_list = image_list_epoch\n",
    "            image_list_epoch = [cv2.resize(tmp, (512, 256), interpolation=cv2.INTER_LINEAR)\n",
    "                                for tmp in image_list_epoch]\n",
    "            image_list_epoch = [tmp - VGG_MEAN for tmp in image_list_epoch]\n",
    "            t_cost = time.time() - t_start\n",
    "            log.info('[Epoch:{:d}] Pre-processing {:d} images, total time consuming: {:.5f}s, \\\n",
    "            Average time per sheet: {:.5f}'.format(\n",
    "                epoch, len(image_path_epoch), t_cost, t_cost / len(image_path_epoch)))\n",
    "\n",
    "            t_start = time.time()\n",
    "            binary_seg_images, instance_seg_images = sess.run(\n",
    "                [binary_seg_ret, instance_seg_ret], feed_dict={input_tensor: image_list_epoch})\n",
    "            print(binary_seg_images.shape, instance_seg_ret.shape)\n",
    "            \n",
    "            \n",
    "            t_cost = time.time() - t_start\n",
    "            log.info('[Epoch:{:d}] Predicting {:d} image lane lines, total time: {:.5f}s, \\\n",
    "            average per time: {:.5f}s'.format(\n",
    "                epoch, len(image_path_epoch), t_cost, t_cost / len(image_path_epoch)))\n",
    "\n",
    "            cluster_time = []\n",
    "            for index, binary_seg_image in enumerate(binary_seg_images):\n",
    "                t_start = time.time()\n",
    "                binary_seg_image = postprocessor.postprocess(binary_seg_image)\n",
    "                mask_image = cluster.get_lane_mask(binary_seg_ret=binary_seg_image,\n",
    "                                                   instance_seg_ret=instance_seg_images[index])\n",
    "                cluster_time.append(time.time() - t_start)\n",
    "                mask_image = cv2.resize(mask_image, (image_vis_list[index].shape[1],\n",
    "                                                     image_vis_list[index].shape[0]),\n",
    "                                        interpolation=cv2.INTER_LINEAR)\n",
    "                \n",
    "                image_name = ops.split(image_path_epoch[index])[1]\n",
    "                image_save_path = ops.join(save_dir, image_name)\n",
    "                image_save_path = ops.splitext(image_save_path)[0]\n",
    "                \n",
    "                _instance_seg_images = np.copy(instance_seg_images)\n",
    "                print(\"mask\", mask_image.shape)\n",
    "                \n",
    "                for i in range(4):\n",
    "                    _instance_seg_images[index][:, :, i] = minmax_scale(instance_seg_images[index][:, :, i])\n",
    "                _embedding_image = np.array(_instance_seg_images[index], np.uint8)\n",
    "                print(\"embedding\", _embedding_image.shape)\n",
    "\n",
    "#                 print(np.max(instance_seg_images))\n",
    "#                 print(np.min(instance_seg_images))\n",
    "#                 m_act = np.max(instance_seg_images)\n",
    "                cv2.imwrite(image_save_path + \"embedding_{}.png\".format(index), _embedding_image[:, :, (2, 1, 0)])\n",
    "                cv2.imwrite(image_save_path + \"binary_{}.png\".format(index), binary_seg_image[:, :] * 255)\n",
    "                \n",
    "                if save_dir is None:\n",
    "                    plt.ion()\n",
    "                    plt.figure('mask_image')\n",
    "                    plt.imshow(mask_image[:, :, (2, 1, 0)])\n",
    "                    plt.figure('src_image')\n",
    "                    plt.imshow(image_vis_list[index][:, :, (2, 1, 0)])\n",
    "                    plt.pause(3.0)\n",
    "                    plt.show()\n",
    "                    plt.ioff()\n",
    "\n",
    "                if save_dir is not None:\n",
    "                    mask_image = cv2.addWeighted(image_vis_list[index], 1.0, mask_image, 1.0, 0)\n",
    "                    image_name = ops.split(image_path_epoch[index])[1]\n",
    "                    image_save_path = ops.join(save_dir, image_name)\n",
    "                    cv2.imwrite(image_save_path, mask_image)\n",
    "\n",
    "            log.info('[Epoch:{:d}] Perform {:d} image lane line clustering, total time: {:.5f}s, \\\n",
    "            average time per sheet: {:.5f}'.format(\n",
    "                epoch, len(image_path_epoch), np.sum(cluster_time), np.mean(cluster_time)))\n",
    "\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lanenet_model import lanenet_merge_model\n",
    "from lanenet_model import lanenet_cluster\n",
    "from lanenet_model import lanenet_postprocess\n",
    "def test_lanenet(image_path, weights_path, use_gpu):\n",
    "    \"\"\"\n",
    "\n",
    "    :param image_path:\n",
    "    :param weights_path:\n",
    "    :param use_gpu:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert ops.exists(image_path), '{:s} not exist'.format(image_path)\n",
    "\n",
    "    log.info('Start reading image data and pre-processing')\n",
    "    t_start = time.time()\n",
    "    # image\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "    # copy image\n",
    "    image_vis = image\n",
    "    image = cv2.resize(image, (512, 256), interpolation=cv2.INTER_LINEAR)\n",
    "    plt.figure('image')\n",
    "    plt.imshow(image[:, :, (2, 1, 0)])\n",
    "    plt.show()\n",
    "    # normalisation. How to compute it??? Average on the sum on each channel for each image in the dataset???\n",
    "    image = image - VGG_MEAN\n",
    "    plt.figure('image-vgg')\n",
    "    plt.imshow(image[:, :, (2, 1, 0)])\n",
    "    plt.show()\n",
    "    log.info('Image is read, time consuming: {:.5f}s'.format(time.time() - t_start))\n",
    "\n",
    "    # take one image\n",
    "    input_tensor = tf.placeholder(dtype=tf.float32, shape=[1, 256, 512, 3], name='input_tensor')\n",
    "    \n",
    "    # update the network parameters? test == No, train == Yes\n",
    "    phase_tensor = tf.constant('test', tf.string)\n",
    "    \n",
    "    # does it containes the LSTM part???\n",
    "    net = lanenet_merge_model.LaneNet(phase=phase_tensor, net_flag='vgg')\n",
    "    \n",
    "    # binary_seg_ret - lane or not-lane image\n",
    "    # instance_seg_ret - pixel embedding ????\n",
    "    binary_seg_ret, instance_seg_ret = net.inference(input_tensor=input_tensor, name='lanenet_model')\n",
    "#     print(binary_seg_ret.shape)\n",
    "#     print(instance_seg_ret.shape)\n",
    "    \n",
    "    #plt.figure('binary_seg_ret')\n",
    "    \n",
    "    #plt.imshow(binary_seg_ret[0])\n",
    "    #     plt.figure('instance_seg_ret0')\n",
    "#     plt.imshow(instance_seg_ret[0][:,:,0])\n",
    "#     plt.figure('instance_seg_ret1')\n",
    "#     plt.imshow(instance_seg_ret[0][:,:,1])\n",
    "#     plt.figure('instance_seg_ret2')\n",
    "#     plt.imshow(instance_seg_ret[0][:,:,2])\n",
    "#     plt.figure('instance_seg_ret3')\n",
    "#     plt.imshow(instance_seg_ret[0][:,:,3])\n",
    "    # binary_seg_ret = tf.Print(binary_seg_ret, [binary_seg_ret[0]], message=\"binary_seg [0]\")\n",
    "\n",
    "    cluster = lanenet_cluster.LaneNetCluster()\n",
    "    postprocessor = lanenet_postprocess.LaneNetPoseProcessor()\n",
    "\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "    # Set sess configuration\n",
    "    if use_gpu:\n",
    "        sess_config = tf.ConfigProto(device_count={'GPU': 0})\n",
    "    else:\n",
    "        sess_config = tf.ConfigProto(device_count={'CPU': 0})\n",
    "    \n",
    "    # prevent using the entire gpu memory for training/inference\n",
    "    sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TEST.GPU_MEMORY_FRACTION\n",
    "    \n",
    "    # don't allocate the entire available memory from the start. \n",
    "    sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "    sess_config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "    sess = tf.Session(config=sess_config)\n",
    "\n",
    "    with sess.as_default():\n",
    "\n",
    "        saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "        t_start = time.time()\n",
    "       \n",
    "        binary_seg_image, instance_seg_image = sess.run([binary_seg_ret, instance_seg_ret],\n",
    "                                                        feed_dict={input_tensor: [image]})\n",
    "        \n",
    "        _instance_seg_image = np.copy(instance_seg_image)\n",
    "        for i in range(4):\n",
    "            _instance_seg_image[0][:, :, i] = minmax_scale(instance_seg_image[0][:, :, i])\n",
    "        _embedding_image = np.array(_instance_seg_image[0], np.uint8)\n",
    "\n",
    "   \n",
    "        plt.figure('src_image')\n",
    "        plt.imshow(image_vis[:, :, (2, 1, 0)])\n",
    "        plt.figure('instance_image')\n",
    "        plt.imshow(_embedding_image[:, :, (2, 1, 0)])\n",
    "        plt.figure('binary_image')\n",
    "        plt.imshow(binary_seg_image[0] * 255, cmap='gray')\n",
    "        plt.show()\n",
    "        \n",
    "        t_cost = time.time() - t_start\n",
    "        log.info('Single image lane line prediction time consuming: {:.5f}s'.format(t_cost))\n",
    "\n",
    "        # remove connected components that are smaller 15 pixels\n",
    "        binary_seg_image[0] = postprocessor.postprocess(binary_seg_image[0], minarea_threshold=15)\n",
    "        mask_image = cluster.get_lane_mask(binary_seg_ret=binary_seg_image[0],\n",
    "                                           instance_seg_ret=instance_seg_image[0])\n",
    "\n",
    "        for i in range(4):\n",
    "            instance_seg_image[0][:, :, i] = minmax_scale(instance_seg_image[0][:, :, i])\n",
    "        embedding_image = np.array(instance_seg_image[0], np.uint8)\n",
    "        print(\"hereeee\")\n",
    "        print(embedding_image.shape)\n",
    "        plt.figure('mask_image')\n",
    "        plt.imshow(mask_image[:, :, (2, 1, 0)])\n",
    "        plt.figure('src_image')\n",
    "        plt.imshow(image_vis[:, :, (2, 1, 0)])\n",
    "        plt.figure('instance_image')\n",
    "        plt.imshow(embedding_image[:, :, (2, 1, 0)])\n",
    "        plt.figure('binary_image')\n",
    "        plt.imshow(binary_seg_image[0] * 255, cmap='gray')\n",
    "        plt.show()\n",
    "\n",
    "    sess.close()\n",
    "    tf.reset_default_graph() \n",
    "\n",
    "return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = '/workspace/storage/projects/lanenet-lane-detection/data/training_data_example/image'\n",
    "weights_path = '/workspace/storage/projects/lanenet-lane-detection/AVM_weights_4_lines/tusimple_lanenet_vgg_2019-03-13-14-53-49.ckpt-50000'\n",
    "is_batch = True\n",
    "batch_size = 8\n",
    "save_dir = '/workspace/storage/projects/lanenet-lane-detection/data/output_test_50k'\n",
    "use_gpu = 1\n",
    "\n",
    "if save_dir is not None and not ops.exists(save_dir):\n",
    "    log.error('{:s} not exist and has been made'.format(save_dir))\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "if is_batch == False:\n",
    "    # test hnet model on single image\n",
    "    test_lanenet(image_path, weights_path, use_gpu)\n",
    "else:\n",
    "    # test hnet model on a batch of image\n",
    "    test_lanenet_batch(image_dir=image_path, weights_path=weights_path,\n",
    "                       save_dir=save_dir, use_gpu=use_gpu, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = np.array([[1,1,1], [0,0,0], [1,0,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(m == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
