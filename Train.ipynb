{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import math\n",
    "import os\n",
    "import os.path as ops\n",
    "import time\n",
    "\n",
    "import cv2\n",
    "import glog as log\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from config import global_config\n",
    "from lanenet_model import lanenet_merge_model\n",
    "from data_provider import lanenet_data_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFG = global_config.cfg\n",
    "VGG_MEAN = [103.939, 116.779, 123.68]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'TEST': {'BATCH_SIZE': 8,\n",
       "  'GPU_MEMORY_FRACTION': 0.8,\n",
       "  'TF_ALLOW_GROWTH': True},\n",
       " 'TRAIN': {'BATCH_SIZE': 8,\n",
       "  'CLASSES_NUMS': 2,\n",
       "  'DISPLAY_STEP': 10,\n",
       "  'EPOCHS': 200010,\n",
       "  'GPU_MEMORY_FRACTION': 0.9,\n",
       "  'IMG_HEIGHT': 256,\n",
       "  'IMG_WIDTH': 512,\n",
       "  'LEARNING_RATE': 0.0005,\n",
       "  'LR_DECAY_RATE': 0.1,\n",
       "  'LR_DECAY_STEPS': 80000,\n",
       "  'MOMENTUM': 0.9,\n",
       "  'TEST_DISPLAY_STEP': 100,\n",
       "  'TF_ALLOW_GROWTH': True,\n",
       "  'VAL_BATCH_SIZE': 8}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CFG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minmax_scale(input_arr):\n",
    "    \"\"\"\n",
    "\n",
    "    :param input_arr:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    min_val = np.min(input_arr)\n",
    "    max_val = np.max(input_arr)\n",
    "\n",
    "    output_arr = (input_arr - min_val) * 255.0 / (max_val - min_val)\n",
    "\n",
    "    return output_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(dataset_dir, weights_path=None, net_flag='vgg'):\n",
    "    \"\"\"\n",
    "\n",
    "    :param dataset_dir:\n",
    "    :param net_flag: choose which base network to use\n",
    "    :param weights_path:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    \n",
    "    #path/train.txt\n",
    "    train_dataset_file = ops.join(dataset_dir, 'train.txt')\n",
    "    val_dataset_file = ops.join(dataset_dir, 'val.txt')\n",
    "\n",
    "    assert ops.exists(train_dataset_file)\n",
    "\n",
    "    train_dataset = lanenet_data_processor.DataSet(train_dataset_file)\n",
    "    val_dataset = lanenet_data_processor.DataSet(val_dataset_file)\n",
    "\n",
    "    with tf.device('/gpu:0'):\n",
    "        input_tensor = tf.placeholder(dtype=tf.float32,\n",
    "                                      shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                             CFG.TRAIN.IMG_WIDTH, 3],\n",
    "                                      name='input_tensor')\n",
    "        binary_label_tensor = tf.placeholder(dtype=tf.int64,\n",
    "                                             shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                                    CFG.TRAIN.IMG_WIDTH, 1],\n",
    "                                             name='binary_input_label')\n",
    "        instance_label_tensor = tf.placeholder(dtype=tf.float32,\n",
    "                                               shape=[CFG.TRAIN.BATCH_SIZE, CFG.TRAIN.IMG_HEIGHT,\n",
    "                                                      CFG.TRAIN.IMG_WIDTH],\n",
    "                                               name='instance_input_label')\n",
    "        phase = tf.placeholder(dtype=tf.string, shape=None, name='net_phase')\n",
    "\n",
    "        net = lanenet_merge_model.LaneNet(net_flag=net_flag, phase=phase)\n",
    "\n",
    "        # calculate the loss\n",
    "        compute_ret = net.compute_loss(input_tensor=input_tensor, binary_label=binary_label_tensor,\n",
    "                                       instance_label=instance_label_tensor, ignore_label=255, name='lanenet_model')\n",
    "        total_loss = compute_ret['total_loss']\n",
    "        binary_seg_loss = compute_ret['binary_seg_loss']\n",
    "        disc_loss = compute_ret['discriminative_loss']\n",
    "        pix_embedding = compute_ret['instance_seg_logits']\n",
    "\n",
    "        # calculate the accuracy\n",
    "        out_logits = compute_ret['binary_seg_logits']\n",
    "        out_logits = tf.nn.softmax(logits=out_logits)\n",
    "        out_logits_out = tf.argmax(out_logits, axis=-1)\n",
    "        out = tf.argmax(out_logits, axis=-1)\n",
    "        out = tf.expand_dims(out, axis=-1)\n",
    "\n",
    "        idx = tf.where(tf.equal(binary_label_tensor, 1))\n",
    "        pix_cls_ret = tf.gather_nd(out, idx)\n",
    "        accuracy = tf.count_nonzero(pix_cls_ret)\n",
    "        accuracy = tf.divide(accuracy, tf.cast(tf.shape(pix_cls_ret)[0], tf.int64))\n",
    "\n",
    "        global_step = tf.Variable(0, trainable=False)\n",
    "        learning_rate = tf.train.exponential_decay(CFG.TRAIN.LEARNING_RATE, global_step,\n",
    "                                                   100000, 0.1, staircase=True)\n",
    "        update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "        with tf.control_dependencies(update_ops):\n",
    "            optimizer = tf.train.MomentumOptimizer(\n",
    "                learning_rate=learning_rate, momentum=0.9).minimize(loss=total_loss,\n",
    "                                                                    var_list=tf.trainable_variables(),\n",
    "                                                                    global_step=global_step)\n",
    "\n",
    "    # Set tf saver\n",
    "    saver = tf.train.Saver()\n",
    "    model_save_dir = '/workspace/storage/projects/lanenet-lane-detection/test_ignore_label'\n",
    "    if not ops.exists(model_save_dir):\n",
    "        os.makedirs(model_save_dir)\n",
    "    train_start_time = time.strftime('%Y-%m-%d-%H-%M-%S', time.localtime(time.time()))\n",
    "    \n",
    "  \n",
    "    \n",
    "    model_name = 'tusimple_lanenet_{:s}_{:s}.ckpt'.format(net_flag, str(train_start_time))\n",
    "    model_save_path = ops.join(model_save_dir, model_name)\n",
    "\n",
    "    # Set tf summary\n",
    "    tboard_save_path = 'tboard/tusimple_lanenet/test_ignore_label/{:s}'.format(net_flag)\n",
    "    if not ops.exists(tboard_save_path):\n",
    "        os.makedirs(tboard_save_path)\n",
    "    train_cost_scalar = tf.summary.scalar(name='train_cost', tensor=total_loss)\n",
    "    val_cost_scalar = tf.summary.scalar(name='val_cost', tensor=total_loss)\n",
    "    train_accuracy_scalar = tf.summary.scalar(name='train_accuracy', tensor=accuracy)\n",
    "    val_accuracy_scalar = tf.summary.scalar(name='val_accuracy', tensor=accuracy)\n",
    "    train_binary_seg_loss_scalar = tf.summary.scalar(name='train_binary_seg_loss', tensor=binary_seg_loss)\n",
    "    val_binary_seg_loss_scalar = tf.summary.scalar(name='val_binary_seg_loss', tensor=binary_seg_loss)\n",
    "    train_instance_seg_loss_scalar = tf.summary.scalar(name='train_instance_seg_loss', tensor=disc_loss)\n",
    "    val_instance_seg_loss_scalar = tf.summary.scalar(name='val_instance_seg_loss', tensor=disc_loss)\n",
    "    learning_rate_scalar = tf.summary.scalar(name='learning_rate', tensor=learning_rate)\n",
    "    train_merge_summary_op = tf.summary.merge([train_accuracy_scalar, train_cost_scalar,\n",
    "                                               learning_rate_scalar, train_binary_seg_loss_scalar,\n",
    "                                               train_instance_seg_loss_scalar])\n",
    "    val_merge_summary_op = tf.summary.merge([val_accuracy_scalar, val_cost_scalar,\n",
    "                                             val_binary_seg_loss_scalar, val_instance_seg_loss_scalar])\n",
    "\n",
    "    # Set sess configuration\n",
    "    sess_config = tf.ConfigProto(allow_soft_placement=True)\n",
    "    sess_config.gpu_options.per_process_gpu_memory_fraction = CFG.TRAIN.GPU_MEMORY_FRACTION\n",
    "    sess_config.gpu_options.allow_growth = CFG.TRAIN.TF_ALLOW_GROWTH\n",
    "    sess_config.gpu_options.allocator_type = 'BFC'\n",
    "\n",
    "    sess = tf.Session(config=sess_config)\n",
    "\n",
    "    summary_writer = tf.summary.FileWriter(tboard_save_path)\n",
    "    summary_writer.add_graph(sess.graph)\n",
    "\n",
    "    # Set the training parameters\n",
    "    train_epochs = CFG.TRAIN.EPOCHS\n",
    "\n",
    "    log.info('Global configuration is as follows:')\n",
    "    log.info(CFG)\n",
    "\n",
    "    with sess.as_default():\n",
    "\n",
    "        tf.train.write_graph(graph_or_graph_def=sess.graph, logdir='',\n",
    "                             name='{:s}/lanenet_model.pb'.format(model_save_dir))\n",
    "\n",
    "        if weights_path is None:\n",
    "            log.info('Training from scratch')\n",
    "            init = tf.global_variables_initializer()\n",
    "            sess.run(init)\n",
    "        else:\n",
    "            log.info('Restore model from last model checkpoint {:s}'.format(weights_path))\n",
    "            saver.restore(sess=sess, save_path=weights_path)\n",
    "\n",
    "        # Load pre-training parameters\n",
    "        if net_flag == 'vgg' and weights_path is None:\n",
    "            pretrained_weights = np.load(\n",
    "                './data/vgg16.npy',\n",
    "                encoding='latin1').item()\n",
    "\n",
    "            for vv in tf.trainable_variables():\n",
    "                weights_key = vv.name.split('/')[-3]\n",
    "                try:\n",
    "                    weights = pretrained_weights[weights_key][0]\n",
    "                    _op = tf.assign(vv, weights)\n",
    "                    sess.run(_op)\n",
    "                except Exception as e:\n",
    "                    continue\n",
    "\n",
    "        train_cost_time_mean = []\n",
    "        val_cost_time_mean = []\n",
    "        \n",
    "        ignore_labels = cv2.imread(\"/workspace/storage/datasets/AVMSnapshots/AVM/ignore_labels.png\")\n",
    "        for epoch in range(train_epochs):\n",
    "            # training part\n",
    "            t_start = time.time()\n",
    "\n",
    "            with tf.device('/cpu:0'):\n",
    "                gt_imgs, binary_gt_labels, instance_gt_labels = train_dataset.next_batch(CFG.TRAIN.BATCH_SIZE, ignore_label=ignore_labels)\n",
    "                \n",
    "                # resized the GTs in order to improve speed, use this resize if you don't have data images size 256x512\n",
    "                \n",
    "#                 gt_imgs = [cv2.resize(tmp,\n",
    "#                                       dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "#                                       dst=tmp,\n",
    "#                                       interpolation=cv2.INTER_LINEAR)\n",
    "#                            for tmp in gt_imgs]\n",
    "\n",
    "                gt_imgs = [tmp - VGG_MEAN for tmp in gt_imgs]\n",
    "                \n",
    "#                 binary_gt_labels = [cv2.resize(tmp,\n",
    "#                                                dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "#                                                dst=tmp,\n",
    "#                                                interpolation=cv2.INTER_NEAREST)\n",
    "#                                     for tmp in binary_gt_labels]\n",
    "\n",
    "                binary_gt_labels = [np.expand_dims(tmp, axis=-1) for tmp in binary_gt_labels]\n",
    "#                 instance_gt_labels = [cv2.resize(tmp,\n",
    "#                                                  dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "#                                                  dst=tmp,\n",
    "#                                                  interpolation=cv2.INTER_NEAREST)\n",
    "#                                       for tmp in instance_gt_labels]\n",
    "            phase_train = 'train'\n",
    "\n",
    "            _, c, train_accuracy, train_summary, binary_loss, instance_loss, embedding, binary_seg_img = \\\n",
    "                sess.run([optimizer, total_loss,\n",
    "                          accuracy,\n",
    "                          train_merge_summary_op,\n",
    "                          binary_seg_loss,\n",
    "                          disc_loss,\n",
    "                          pix_embedding,\n",
    "                          out_logits_out],\n",
    "                         feed_dict={input_tensor: gt_imgs,\n",
    "                                    binary_label_tensor: binary_gt_labels,\n",
    "                                    instance_label_tensor: instance_gt_labels,\n",
    "                                    phase: phase_train})\n",
    "\n",
    "            if math.isnan(c) or math.isnan(binary_loss) or math.isnan(instance_loss):\n",
    "                log.error('cost is: {:.5f}'.format(c))\n",
    "                log.error('binary cost is: {:.5f}'.format(binary_loss))\n",
    "                log.error('instance cost is: {:.5f}'.format(instance_loss))\n",
    "                cv2.imwrite('nan_image.png', gt_imgs[0] + VGG_MEAN)\n",
    "                cv2.imwrite('nan_instance_label.png', instance_gt_labels[0])\n",
    "                cv2.imwrite('nan_binary_label.png', binary_gt_labels[0] * 255)\n",
    "                return\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                cv2.imwrite('image.png', gt_imgs[0] + VGG_MEAN)\n",
    "                cv2.imwrite('binary_label.png', binary_gt_labels[0] * 255)\n",
    "                cv2.imwrite('instance_label.png', instance_gt_labels[0])\n",
    "                cv2.imwrite('binary_seg_img.png', binary_seg_img[0] * 255)\n",
    "\n",
    "                for i in range(4):\n",
    "                    embedding[0][:, :, i] = minmax_scale(embedding[0][:, :, i])\n",
    "                embedding_image = np.array(embedding[0], np.uint8)\n",
    "                cv2.imwrite('embedding.png', embedding_image)\n",
    "\n",
    "            cost_time = time.time() - t_start\n",
    "            train_cost_time_mean.append(cost_time)\n",
    "            summary_writer.add_summary(summary=train_summary, global_step=epoch)\n",
    "\n",
    "            # validation part\n",
    "            with tf.device('/cpu:0'):\n",
    "                gt_imgs_val, binary_gt_labels_val, instance_gt_labels_val \\\n",
    "                    = val_dataset.next_batch(CFG.TRAIN.VAL_BATCH_SIZE, ignore_label=ignore_labels)\n",
    "#                 gt_imgs_val = [cv2.resize(tmp,\n",
    "#                                           dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "#                                           dst=tmp,\n",
    "#                                           interpolation=cv2.INTER_LINEAR)\n",
    "#                                for tmp in gt_imgs_val]\n",
    "                gt_imgs_val = [tmp - VGG_MEAN for tmp in gt_imgs_val]\n",
    "#                 binary_gt_labels_val = [cv2.resize(tmp,\n",
    "#                                                    dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "#                                                    dst=tmp)\n",
    "#                                         for tmp in binary_gt_labels_val]\n",
    "                binary_gt_labels_val = [np.expand_dims(tmp, axis=-1) for tmp in binary_gt_labels_val]\n",
    "#                 instance_gt_labels_val = [cv2.resize(tmp,\n",
    "#                                                      dsize=(CFG.TRAIN.IMG_WIDTH, CFG.TRAIN.IMG_HEIGHT),\n",
    "#                                                      dst=tmp,\n",
    "#                                                      interpolation=cv2.INTER_NEAREST)\n",
    "#                                           for tmp in instance_gt_labels_val]\n",
    "            phase_val = 'test'\n",
    "\n",
    "            t_start_val = time.time()\n",
    "            c_val, val_summary, val_accuracy, val_binary_seg_loss, val_instance_seg_loss = \\\n",
    "                sess.run([total_loss, val_merge_summary_op, accuracy, binary_seg_loss, disc_loss],\n",
    "                         feed_dict={input_tensor: gt_imgs_val,\n",
    "                                    binary_label_tensor: binary_gt_labels_val,\n",
    "                                    instance_label_tensor: instance_gt_labels_val,\n",
    "                                    phase: phase_val})\n",
    "\n",
    "            if epoch % 100 == 0:\n",
    "                cv2.imwrite('test_image.png', gt_imgs_val[0] + VGG_MEAN)\n",
    "\n",
    "            summary_writer.add_summary(val_summary, global_step=epoch)\n",
    "\n",
    "            cost_time_val = time.time() - t_start_val\n",
    "            val_cost_time_mean.append(cost_time_val)\n",
    "\n",
    "            if epoch % CFG.TRAIN.DISPLAY_STEP == 0:\n",
    "                log.info('Epoch: {:d} total_loss= {:6f} binary_seg_loss= {:6f} instance_seg_loss= {:6f} accuracy= {:6f}'\n",
    "                         ' mean_cost_time= {:5f}s '.\n",
    "                         format(epoch + 1, c, binary_loss, instance_loss, train_accuracy,\n",
    "                                np.mean(train_cost_time_mean)))\n",
    "                train_cost_time_mean.clear()\n",
    "\n",
    "            if epoch % CFG.TRAIN.TEST_DISPLAY_STEP == 0:\n",
    "                log.info('Epoch_Val: {:d} total_loss= {:6f} binary_seg_loss= {:6f} '\n",
    "                         'instance_seg_loss= {:6f} accuracy= {:6f} '\n",
    "                         'mean_cost_time= {:5f}s '.\n",
    "                         format(epoch + 1, c_val, val_binary_seg_loss, val_instance_seg_loss, val_accuracy,\n",
    "                                np.mean(val_cost_time_mean)))\n",
    "                val_cost_time_mean.clear()\n",
    "\n",
    "            if epoch % 2000 == 0:\n",
    "                  # Save checkpoint, graph.pb and tensorboard\n",
    "#                 saver.save(sess, model_save_path + \"/model.ckpt\")\n",
    "#                 tf.train.write_graph(sess.graph.as_graph_def(), model_save_path + \"/\", \"graph.pb\")\n",
    "                saver.save(sess=sess, save_path=model_save_path, global_step=epoch)\n",
    "    sess.close()\n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 15:31:06.595409 22632 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "W0328 15:31:06.599436 22632 deprecation.py:323] From /workspace/storage/projects/lanenet-lane-detection/encoder_decoder_model/cnn_basenet.py:316: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.batch_normalization instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0328 15:31:07.229960 22632 deprecation.py:323] From /workspace/storage/projects/lanenet-lane-detection/encoder_decoder_model/cnn_basenet.py:370: conv2d_transpose (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.conv2d_transpose instead.\n",
      "W0328 15:31:07.328643 22632 deprecation.py:323] From /workspace/storage/projects/lanenet-lane-detection/lanenet_model/lanenet_merge_model.py:113: Print (from tensorflow.python.ops.logging_ops) is deprecated and will be removed after 2018-08-20.\n",
      "Instructions for updating:\n",
      "Use tf.print instead of tf.Print. Note that tf.print returns a no-output operator that directly prints the output. Outside of defuns or eager mode, this operator will not be executed unless it is directly specified in session.run or used as a control dependency for other operators. This is only a concern in graph mode. Below is an example of how to ensure tf.print executes in graph mode:\n",
      "```python\n",
      "    sess = tf.Session()\n",
      "    with sess.as_default():\n",
      "        tensor = tf.range(10)\n",
      "        print_op = tf.print(tensor)\n",
      "        with tf.control_dependencies([print_op]):\n",
      "          out = tf.add(tensor, tensor)\n",
      "        sess.run(out)\n",
      "    ```\n",
      "Additionally, to use tf.print in python 2.7, users must make sure to import\n",
      "the following:\n",
      "\n",
      "  `from __future__ import print_function`\n",
      "\n",
      "W0328 15:31:07.352671 22632 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/losses/losses_impl.py:209: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0328 15:31:07.413397 22632 deprecation.py:323] From /workspace/storage/projects/lanenet-lane-detection/lanenet_model/lanenet_discriminative_loss.py:53: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "W0328 15:31:08.643364 22632 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "W0328 15:31:09.985370 22632 gradients_impl.py:110] /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/gradients_impl.py:110: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n",
      "\n",
      "I0328 15:31:13.300534 22632 <ipython-input-5-dab9edde274b>:111] Global configuration is as follows:\n",
      "I0328 15:31:13.301756 22632 <ipython-input-5-dab9edde274b>:112] {'TRAIN': {'LEARNING_RATE': 0.0005, 'LR_DECAY_STEPS': 80000, 'MOMENTUM': 0.9, 'CLASSES_NUMS': 2, 'BATCH_SIZE': 8, 'EPOCHS': 200010, 'DISPLAY_STEP': 10, 'IMG_WIDTH': 512, 'LR_DECAY_RATE': 0.1, 'GPU_MEMORY_FRACTION': 0.9, 'IMG_HEIGHT': 256, 'TEST_DISPLAY_STEP': 100, 'VAL_BATCH_SIZE': 8, 'TF_ALLOW_GROWTH': True}, 'TEST': {'TF_ALLOW_GROWTH': True, 'BATCH_SIZE': 8, 'GPU_MEMORY_FRACTION': 0.8}}\n",
      "I0328 15:31:14.845717 22632 <ipython-input-5-dab9edde274b>:124] Restore model from last model checkpoint /workspace/storage/projects/lanenet-lane-detection/weights/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000\n",
      "W0328 15:31:14.847007 22632 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/training/saver.py:1266: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0328 15:31:14.854346 22632 saver.py:1270] Restoring parameters from /workspace/storage/projects/lanenet-lane-detection/weights/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000\n",
      "W0328 15:31:20.625869 22632 <ipython-input-4-a0762d2f7b11>:10] /usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:10: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "\n",
      "I0328 15:31:21.526554 22632 <ipython-input-5-dab9edde274b>:256] Epoch: 1 total_loss= 60.747341 binary_seg_loss= 100.497826 instance_seg_loss= 18.752094 accuracy= 0.083345 mean_cost_time= 5.308519s \n",
      "I0328 15:31:21.527314 22632 <ipython-input-5-dab9edde274b>:264] Epoch_Val: 1 total_loss= 52.065243 binary_seg_loss= 82.818176 instance_seg_loss= 19.067554 accuracy= 0.099542 mean_cost_time= 0.807670s \n",
      "E0328 15:31:23.213129 22632 ultratb.py:149] Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n",
      "I0328 15:31:23.218388 22632 ultratb.py:1111] \n",
      "Unfortunately, your original traceback can not be constructed.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 3291, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-6-fd96f0356d04>\", line 6, in <module>\n",
      "    train_net(dataset_dir, weights_path, net_flag=net)\n",
      "  File \"<ipython-input-5-dab9edde274b>\", line 188, in train_net\n",
      "    phase: phase_train})\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 929, in run\n",
      "    run_metadata_ptr)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1152, in _run\n",
      "    feed_dict_tensor, options, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1328, in _do_run\n",
      "    run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1334, in _do_call\n",
      "    return fn(*args)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1319, in _run_fn\n",
      "    options, feed_dict, fetch_list, target_list, run_metadata)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\", line 1407, in _call_tf_sessionrun\n",
      "    run_metadata)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/interactiveshell.py\", line 2033, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 313, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/IPython/core/ultratb.py\", line 347, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1453, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 1410, in getframeinfo\n",
      "    filename = getsourcefile(frame) or getfile(frame)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 672, in getsourcefile\n",
      "    if getattr(getmodule(object, filename), '__loader__', None) is not None:\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 715, in getmodule\n",
      "    f = getabsfile(module)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 684, in getabsfile\n",
      "    _filename = getsourcefile(object) or getfile(object)\n",
      "  File \"/usr/lib/python3.5/inspect.py\", line 662, in getsourcefile\n",
      "    all_bytecode_suffixes += importlib.machinery.OPTIMIZED_BYTECODE_SUFFIXES[:]\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    }
   ],
   "source": [
    "dataset_dir = '/workspace/storage/datasets/AVMSnapshots/AVM/'\n",
    "net = 'vgg'\n",
    "weights_path = '/workspace/storage/projects/lanenet-lane-detection/weights/tusimple_lanenet_vgg_2018-10-19-13-33-56.ckpt-200000'\n",
    "\n",
    "# train lanenet\n",
    "train_net(dataset_dir, weights_path, net_flag=net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
